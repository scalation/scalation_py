{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "678143b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL FFNN\n",
      "Pred Length:  4\n",
      "lr 0.01\n",
      "sl 8\n",
      "model_dim 256\n",
      "layers 16\n",
      "Use CPU\n",
      "testing : ModelRun_class 'models.FFNN.FFNN'_custom_lr0.01_ftM_sl8_ll4_pl4_dm256_nh8_el16_dl15_df2048_fc3_ebtimeF_dtTrue_test_0\n",
      "Average sMAPE: 50.11457800865173-------Average MAE: 0.351196-------Average realMAE: 1969.8878\n",
      "------------------------------------------\n",
      "Use CPU\n",
      "testing : ModelRun_class 'models.FFNN.FFNN'_custom_lr0.01_ftM_sl8_ll4_pl4_dm256_nh8_el16_dl15_df2048_fc3_ebtimeF_dtTrue_test_1\n",
      "Average sMAPE: 60.44306010007858-------Average MAE: 0.4417961-------Average realMAE: 2478.0715\n",
      "------------------------------------------\n",
      "Use CPU\n",
      "testing : ModelRun_class 'models.FFNN.FFNN'_custom_lr0.01_ftM_sl8_ll4_pl4_dm256_nh8_el16_dl15_df2048_fc3_ebtimeF_dtTrue_test_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [05:54<00:00, 354.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sMAPE: 71.88806682825089-------Average MAE: 0.5832344-------Average realMAE: 3271.4111\n",
      "------------------------------------------\n",
      "---Best (realMAE, MAE, SMAPE) for 4 pred length FFNN----is----[1969.8878, 0.351196, 50.11457800865173] with 0.01 8 256 16 [59.919995069503784, 32.124221324920654, 55.03765940666199, 53.37643623352051] [0.42918655, 0.20225349, 0.392744, 0.38059992] [2407.3433, 1134.457, 2202.9343, 2134.817]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from models.FFNN import FFNN\n",
    "from models.LSTM import LSTM\n",
    "from models.GRU import GRU\n",
    "from models.LSTM_Seq2Seq import LSTM_Seq2Seq\n",
    "from models.GRU_Seq2Seq import GRU_Seq2Seq\n",
    "from models.LSTM_Seq2Seq_Att import LSTM_Seq2Seq_Att\n",
    "from models.GRU_Seq2Seq_Att import GRU_Seq2Seq_Att\n",
    "from models.Transformer import Transformer\n",
    "from models.Informer import Informer\n",
    "from models.FEDformer import FEDformer\n",
    "from models.Autoformer import Autoformer\n",
    "from models.RandomWalk import RandomWalk\n",
    "from models.PatchTST import PatchTST\n",
    "from models.Dlinear import Dlinear\n",
    "from models.Nlinear import Nlinear\n",
    "import torch\n",
    "import numpy as np\n",
    "from exp.exp_main import Exp_Main\n",
    "\n",
    "\"\"\"\n",
    "This notebook runs the experiments by setting up confuguration with different hyperparameters.\n",
    "\"\"\"\n",
    "\n",
    "model_dict = {\n",
    "            'Autoformer': Autoformer,\n",
    "            'Transformer': Transformer,\n",
    "            'Informer': Informer,\n",
    "            'FEDformer': FEDformer,\n",
    "            'Transformer': Transformer,\n",
    "            \"Dlinear\": Dlinear,\n",
    "            \"Nlinear\": Nlinear,\n",
    "            \"FFNN\": FFNN,\n",
    "            \"LSTM\": LSTM,\n",
    "            \"GRU\": GRU,\n",
    "            \"LSTM_Seq2Seq\": LSTM_Seq2Seq,\n",
    "            \"GRU_Seq2Seq\": GRU_Seq2Seq,\n",
    "            \"LSTM_Seq2Seq_Att\": LSTM_Seq2Seq_Att,\n",
    "            \"GRU_Seq2Seq_Att\": GRU_Seq2Seq_Att,\n",
    "            \"PatchTST\":PatchTST,\n",
    "            \"RandomWalk\":RandomWalk\n",
    "}\n",
    "dataset_dict = {\n",
    "    \"covid_weekly\":7,\n",
    "    \"national_illness\":7\n",
    "}\n",
    "global_dataset = \"covid_weekly\"\n",
    "in_out_dim = dataset_dict[global_dataset]\n",
    "\n",
    "import random\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "lr_test = 0.0001\n",
    "batch_test = 32\n",
    "lags_test = 7\n",
    "hiddenUnit_test = 256\n",
    "reasonable_params_dict = {\"FFNN\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"LSTM\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"GRU\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"GRU_Seq2Seq\":[[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"LSTM_Seq2Seq\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"LSTM_Seq2Seq_Att\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"GRU_Seq2Seq_Att\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"Transformer\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"RandomWalk\": [[0.001], [4], [100],[1]],\n",
    "                          \"Informer\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]], \n",
    "                          \"Autoformer\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"FEDformer\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"Dlinear\": [[lr_test], [lags_test], [100],[batch_test]],#no hidden units\n",
    "                          \"PatchTST\": [[lr_test], [lags_test], [hiddenUnit_test],[batch_test]],\n",
    "                          \"Nlinear\": [[lr_test], [lags_test], [100],[batch_test]]} #no hidden units\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "results_dict = {4:{\"PatchTST\":[100,100,100],\"FEDformer\":[100,100,100],\"Transformer\":[100,100,100],\"Dlinear\":[100,100,100],\"Nlinear\":[100,100,100],\"Informer\":[100,100,100],\"Autoformer\":[100,100,100],\"FFNN\":[100,100,100],\"LSTM\":[100,100,100],\"GRU\":[100,100,100],\n",
    "                    \"GRU_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq_Att\":[100,100,100],\"GRU_Seq2Seq_Att\":[100,100,100],\"RandomWalk\":[100,100,100]},\n",
    "                24:{\"PatchTST\":[100,100,100],\"FEDformer\":[100,100,100],\"Transformer\":[100,100,100],\"Dlinear\":[100,100,100],\"Nlinear\":[100,100,100],\"Informer\":[100,100,100],\"Autoformer\":[100,100,100],\"FFNN\":[100,100,100],\"LSTM\":[100,100,100],\"GRU\":[100,100,100],\n",
    "                    \"GRU_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq_Att\":[100,100,100],\"GRU_Seq2Seq_Att\":[100,100,100],\"RandomWalk\":[100,100,100]},\n",
    "                36:{\"PatchTST\":[100,100,100],\"FEDformer\":[100,100,100],\"Dlinear\":[100,100,100],\"Nlinear\":[100,100,100],\"Informer\":[100,100,100],\"Autoformer\":[100,100,100],\"FFNN\":[100,100,100],\"LSTM\":[100,100,100],\"GRU\":[100,100,100],\n",
    "                    \"GRU_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq\":[100,100,100],\"Transformer\":[100,100,100],\n",
    "                    \"LSTM_Seq2Seq_Att\":[100,100,100],\"GRU_Seq2Seq_Att\":[100,100,100],\"RandomWalk\":[100,100,100]}, \n",
    "                48:{\"PatchTST\":[100,100,100],\"FEDformer\":[100,100,100],\"Dlinear\":[100,100,100],\"Nlinear\":[100,100,100],\"Informer\":[100,100,100],\"Transformer\":[100,100,100],\"Autoformer\":[100,100,100],\"FFNN\":[100,100,100],\"LSTM\":[100,100,100],\"GRU\":[100,100,100],\n",
    "                    \"GRU_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq_Att\":[100,100,100],\"GRU_Seq2Seq_Att\":[100,100,100],\"RandomWalk\":[100,100,100]},\n",
    "                60:{\"PatchTST\":[100,100,100],\"FEDformer\":[100,100,100],\"Dlinear\":[100,100,100],\"Nlinear\":[100,100,100],\"Informer\":[100,100,100],\"Transformer\":[100,100,100],\"Autoformer\":[100,100,100],\"FFNN\":[100,100,100],\"LSTM\":[100,100,100],\"GRU\":[100,100,100],\n",
    "                    \"GRU_Seq2Seq\":[100,100,100],\"LSTM_Seq2Seq\":[100,100,100],\n",
    "                    \"LSTM_Seq2Seq_Att\":[100,100,100],\"GRU_Seq2Seq_Att\":[100,100,100],\"RandomWalk\":[100,100,100]}}\n",
    "for m in tqdm([\"FFNN\"]):\n",
    "    for pl in [4]:\n",
    "        print(\"MODEL\",m)\n",
    "        figs = \"\"\n",
    "        print(\"Pred Length: \",pl)\n",
    "        for lr in reasonable_params_dict[m][0]: #.0001\n",
    "            print(\"lr\",lr)\n",
    "            for sl in reasonable_params_dict[m][1]: # 336,156,96,36\n",
    "                print(\"sl\",sl)\n",
    "                for model_dim in reasonable_params_dict[m][2]:\n",
    "                    print(\"model_dim\",model_dim)\n",
    "                    for layers in reasonable_params_dict[m][3]:\n",
    "                        print(\"layers\",layers)\n",
    "\n",
    "                        class Configs(object):\n",
    "                            train_ratio=0.7\n",
    "                            test_ratio=0.3\n",
    "                            units_layer1 = 32 #for FFNN\n",
    "                            units_layer2=64 #for FFNN\n",
    "                            task_name = 'long_term_forecast'\n",
    "                            is_training=True\n",
    "                            root_path=\"datasets/\"\n",
    "                            data_path=global_dataset + \".csv\" \n",
    "                            model_id=\"ModelRun\"\n",
    "                            model=model_dict[m]\n",
    "                            data=\"custom\" \n",
    "                            features='M' \n",
    "                            seq_len=sl \n",
    "                            label_len=sl-pl if m==\"FEDformer\" and sl==96 > 0 else pl\n",
    "                            pred_len=pl\n",
    "                            e_layers=layers\n",
    "                            d_layers=layers-1\n",
    "                            factor=3 \n",
    "                            enc_in=in_out_dim \n",
    "                            dec_in=in_out_dim \n",
    "                            c_out=in_out_dim\n",
    "                            train_epochs=20\n",
    "                            target = \"OT\" if global_dataset == \"national_illness\" else \"new_cases\"\n",
    "                            freq='h'\n",
    "                            checkpoints='checkpoints/'\n",
    "                            bucket_size=4\n",
    "                            n_hashes=4\n",
    "                            d_model=model_dim\n",
    "                            n_heads=8\n",
    "                            d_ff=2048\n",
    "                            distil=True \n",
    "                            dropout=0.05\n",
    "                            embed='timeF'\n",
    "                            activation='gelu'\n",
    "                            output_attention=False\n",
    "                            num_workers=1\n",
    "                            itr=3\n",
    "                            kernel_size = 3\n",
    "                            batch_size=32\n",
    "                            patience=3\n",
    "                            learning_rate=lr\n",
    "                            des='test'\n",
    "                            loss='mse'\n",
    "                            lradj='type1'\n",
    "                            use_amp=False\n",
    "                            use_gpu=True\n",
    "                            gpu=0\n",
    "                            use_multi_gpu=False\n",
    "                            wavelet = 0\n",
    "                            ab = 0\n",
    "                            modes = 64\n",
    "                            mode_select = 'random'\n",
    "                            version = 'Fourier'\n",
    "                            #version = 'Wavelets'\n",
    "                            moving_avg = [12, 24]\n",
    "                            L = 3\n",
    "                            base = 'legendre'\n",
    "                            cross_activation = 'tanh'\n",
    "                            individual=False\n",
    "                            layer_dim = layers\n",
    "\n",
    "                        args = Configs()\n",
    "\n",
    "                        args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "                        if args.use_gpu and args.use_multi_gpu:\n",
    "                            args.devices = args.devices.replace(' ', '')\n",
    "                            device_ids = args.devices.split(',')\n",
    "                            args.device_ids = [int(id_) for id_ in device_ids]\n",
    "                            args.gpu = args.device_ids[0]\n",
    "                        Exp = Exp_Main\n",
    "                        if args.is_training:\n",
    "                            for ii in range(args.itr):\n",
    "                                # setting record of experiments\n",
    "                                setting = '{}_{}_{}_lr{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}_{}'.format(\n",
    "                                    args.model_id,\n",
    "                                    args.model,\n",
    "                                    args.data,\n",
    "                                    args.learning_rate,\n",
    "                                    args.features,\n",
    "                                    args.seq_len,\n",
    "                                    args.label_len,\n",
    "                                    args.pred_len,\n",
    "                                    args.d_model,\n",
    "                                    args.n_heads,\n",
    "                                    args.e_layers,\n",
    "                                    args.d_layers,\n",
    "                                    args.d_ff,\n",
    "                                    args.factor,\n",
    "                                    args.embed,\n",
    "                                    args.distil,\n",
    "                                    args.des, ii)\n",
    "\n",
    "                                exp = Exp(args) \n",
    "                                setting= setting.replace('<', '').replace('>', '')\n",
    "                               \n",
    "                                #print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "                                exp.train(setting)\n",
    "\n",
    "                                print('testing : {}'.format(setting))\n",
    "                                realMAE, mae, smape = exp.test(setting)\n",
    "                                print(\"Average sMAPE: \"+str(np.mean(smape))\n",
    "                                     +\"-------Average MAE: \"+str(np.mean(mae))\n",
    "                                     +\"-------Average realMAE: \"+str(np.mean(realMAE)))\n",
    "                                if results_dict[pl][m][2] > np.mean(smape):\n",
    "                                    results_dict[pl][m] = [np.mean(realMAE), np.mean(mae), np.mean(smape)]\n",
    "                                    figs = str(lr) + \" \" +  str(sl) + \" \" + str(model_dim) + \" \" + str(layers)+ \" \" +str(smape)+ \" \" +str(mae)+ \" \" +str(realMAE)\n",
    "                              \n",
    "                                print(\"------------------------------------------\")\n",
    "                                torch.cuda.empty_cache()\n",
    "        print(\"---Best (realMAE, MAE, SMAPE) for \" + str(pl) + \" pred length \" + str(m) + \"----is----\"+str(results_dict[pl][m])+\" with \"+ str(figs) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f56e224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
