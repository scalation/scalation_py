{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56933ae9",
   "metadata": {
    "id": "56933ae9"
   },
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from metrics import *\n",
    "from typing import Callable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd61142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(x: int)-> int:\n",
    "    \"\"\" \n",
    "    This function performs normalization on the data\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    x: int\n",
    "        the integer data \n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    x: int\n",
    "        the normalized data\n",
    "        \n",
    "    \"\"\" \n",
    "    if (x != 0 and x != np.nan):\n",
    "        return np.log(x)\n",
    "    if (x == 0 and x != np.nan): #checks for zeros\n",
    "        return 0\n",
    "    if x == np.nan: #checks for nan values\n",
    "        return np.nan\n",
    "      \n",
    "def itransf(x: int)-> int:\n",
    "    \"\"\" \n",
    "    This function performs inverse normalization on the data\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    x: int\n",
    "        the normalized data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    x: int\n",
    "        original data (unnormalized data)\n",
    "        \n",
    "    \"\"\" \n",
    "    return np.exp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b050b21",
   "metadata": {
    "id": "4b050b21"
   },
   "outputs": [],
   "source": [
    "def forecast_SARIMA(window: int, n_train: int, p: int, d: int, q: int, ps: int, ds: int, qs: int, m: int, y: str, h_max: int, transf: Callable[[float], float], itransf: Callable[[float], float] , file_name: str )-> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    This function uses the SARIMAX model from statsmodels. It forecasts 'h' time steps in future.\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    window : int\n",
    "        window number\n",
    "    n_train : int\n",
    "        the size of training set\n",
    "    p : int\n",
    "        the value for auto regression order\n",
    "    d : int\n",
    "        the value for differencing \n",
    "    q : int\n",
    "        the value for moving average order\n",
    "    ps : int\n",
    "        the value for seasonal auto regression order\n",
    "    ds : int\n",
    "        the value for seasonal differencing \n",
    "    qs : int\n",
    "        the value for seasonal moving average order\n",
    "    m : int\n",
    "        the number of time steps for a single seasonal period\n",
    "    y : str\n",
    "        the forecasted variable\n",
    "    h_max : int\n",
    "        the maximum number of forecasted horizons\n",
    "    transf: Callable[[float], float]\n",
    "        the definition for transformation\n",
    "    itransf: Callable[[float], float]\n",
    "        the definition for inverse transformation\n",
    "    file_name: str\n",
    "        the file name for the data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    forecast_f : pd.DataFrame\n",
    "      DataFrame containing the forecasted variable for 'h_max' horizons.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    df_US = pd.read_csv(file_name)\n",
    "    df_US.index = pd.to_datetime(df_US['date'])\n",
    "    df_US = df_US.drop(columns=['date'])\n",
    "    \n",
    "    #Apply transformation\n",
    "    df_US_transf = pd.DataFrame()\n",
    "    for col in df_US.columns:\n",
    "        df_US_transf[col] = df_US[col].apply(lambda x: transf(x))\n",
    "\n",
    "    df_y = df_US_transf[y]\n",
    "\n",
    "    # Its a moving window that starts from the window value till the train size plus the 'h' time steps in future\n",
    "    df_window = df_y[int(window-1):int(window-1+n_train+h_max)]\n",
    "\n",
    "    i = h_max-1\n",
    "\n",
    "    #Defining train data\n",
    "    col_train = df_y.loc[df_window.index][0:n_train]\n",
    "\n",
    "    model = SARIMAX(col_train, order=(p,d,q), seasonal_order=(ps,ds,qs,m), enforce_stationarity=False, enforce_invertibility=False)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    forecast = model_fit.predict(len(col_train), len(col_train)+i)\n",
    "\n",
    "    forecast = itransf(forecast)\n",
    "    forecast_f = forecast.to_frame()\n",
    "\n",
    "    df_forecast = forecast_f.rename(columns= {'predicted_mean': y})\n",
    "\n",
    "    \n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39da659a",
   "metadata": {
    "id": "39da659a"
   },
   "outputs": [],
   "source": [
    "def window_results(n_train: int, n_test: int, p: int, d: int, q: int, ps: int, ds: int, qs: int, m: int, \n",
    "                     y: str, h_max: int, transf: Callable[[float], float] ,itransf: Callable[[float], float], file_name: str)-> pd.DataFrame:\n",
    "     \n",
    "    \"\"\"\n",
    "    A function that returns the weekly prediction for each window. \n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    n_train : int\n",
    "        the size of training set\n",
    "    n_test : int\n",
    "        the size of testing set\n",
    "    p : int\n",
    "        the value for auto regression order\n",
    "    d : int\n",
    "        the value for differencing \n",
    "    q : int\n",
    "        the value for moving average order\n",
    "    ps : int\n",
    "        the value for seasonal auto regression order\n",
    "    ds : int\n",
    "        the value for seasonal differencing \n",
    "    qs : int\n",
    "        the value for seasonal moving average order\n",
    "    m : int\n",
    "        the number of time steps for a single seasonal period\n",
    "    y : str\n",
    "        the forecasted variable\n",
    "    h_max : int\n",
    "        the maximum number of forecasted horizons\n",
    "    transf: Callable[[float], float]\n",
    "        the definition for transformation\n",
    "    itransf: Callable[[float], float]\n",
    "        the definition for inverse transformation\n",
    "    file_name: str\n",
    "        the file name for the data\n",
    "        \n",
    "    Returned Values\n",
    "    ----------\n",
    "    temp_results : pd.DataFrame\n",
    "        A DataFrame containing weekly predictions for each window\n",
    "\n",
    "    \"\"\"  \n",
    "    temp_results = pd.DataFrame()\n",
    "    for i in range(n_test):\n",
    "        window = i + 1\n",
    "        predict_current = forecast_SARIMA(window, n_train, p, d, q, ps, ds, qs, m, y, h_max, transf, itransf, file_name)\n",
    "        predict_current = predict_current.rename(columns={str(y):\"window_\"+str(window)})\n",
    "        temp_results = pd.concat([temp_results, predict_current], axis=1)\n",
    "#         print(temp_results)\n",
    "    return temp_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f9a7f14",
   "metadata": {
    "id": "8f9a7f14"
   },
   "outputs": [],
   "source": [
    "def output_h(temp_results: pd.DataFrame, h: int, n_test:int)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function processes the 'temp_results' DataFrame, which contains predictions for h weeks ahead for each window, and organizes the data into a single column for each horizon.\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    temp_results : pd.DataFrame\n",
    "        the dataframe that has h weeks ahead prediction for each window\n",
    "    h : int\n",
    "        horizon value\n",
    "    n_test : int\n",
    "        the size of testing set\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results_python : pd.DataFrame\n",
    "        Dataframe for each horizon.  \n",
    "\n",
    "    \"\"\" \n",
    "    n_iter = n_test-h+1\n",
    "    df_results = []\n",
    "    if h==1:\n",
    "        for i in range(int(n_iter)):\n",
    "          window = i + 1\n",
    "          current_results = temp_results[['window_'+str(window)]].dropna()\n",
    "          current_results = current_results.rename(columns={'window_'+str(window): \"h=\"+str(h)})\n",
    "          df_results.append(pd.DataFrame(current_results.iloc[0]).transpose())\n",
    "    if h>1:\n",
    "        for i in range(int(h-1)):\n",
    "          window = i + 1\n",
    "          current_results = temp_results[['window_'+str(window)]].dropna()\n",
    "          current_results = current_results.rename(columns={'window_'+str(window): \"h=\"+str(h)})\n",
    "          df_results.append(pd.DataFrame(current_results.iloc[0]).transpose())\n",
    "\n",
    "        for i in range(int(n_iter)):\n",
    "          window = i + 1\n",
    "          current_results = temp_results[['window_'+str(window)]].dropna()\n",
    "          current_results = current_results.rename(columns={'window_'+str(window): \"h=\"+str(h)})\n",
    "          df_results.append(pd.DataFrame(current_results.iloc[int(h-1)]).transpose())\n",
    "    df_results_python = pd.concat(df_results,axis=0)\n",
    "    return df_results_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00437a0a",
   "metadata": {
    "id": "00437a0a"
   },
   "outputs": [],
   "source": [
    "def predict_table(n_test: int, temp_results:pd.DataFrame, h_max: int)-> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A function that iterates through each horizon and combines the predictions for each horizon into a final DataFrame that has 'h' columns for each week.\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    n_test : int\n",
    "        the size of testing set\n",
    "    temp_results : pd.DataFrame\n",
    "        the dataframe that has h weeks ahead prediction for each window\n",
    "    h_max : int\n",
    "        the maximum number of forecasted horizons\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_final_forecast : pd.DataFrame\n",
    "        DataFrame presenting the h weeks ahead prediction for each week.\n",
    "\n",
    "    \"\"\" \n",
    "    df_final_forecast = pd.DataFrame()\n",
    "    for h in range(1,h_max+1):\n",
    "        df_current = output_h(temp_results, h, n_test)\n",
    "        df_final_forecast = pd.concat([df_final_forecast, df_current], axis=1)\n",
    "    return df_final_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "621c01a6",
   "metadata": {
    "id": "621c01a6"
   },
   "outputs": [],
   "source": [
    "def smape_results(df_final_forecast: pd.DataFrame ,y: str, file_name: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the sMAPE score using the sMAPE definition between the original data and the predictions for each horizon\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame containing h weeks ahead prediction for each week\n",
    "    y : str\n",
    "        the forecasted variable\n",
    "    file_name: str\n",
    "        the file name for the data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with SMAPE scores for each horizon and the average SMAPE score.\n",
    "        \n",
    "    \"\"\"  \n",
    "    df_US = pd.read_csv(file_name)\n",
    "    df_US.index = pd.to_datetime(df_US['date'])\n",
    "    h_level = df_final_forecast.columns.to_list()\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = df_US.loc[df_final_forecast.index][y]\n",
    "        y_pred = df_final_forecast[cols]\n",
    "        value = smape(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70eade94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_results(df_final_forecast: pd.DataFrame ,y: str, file_name: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the MAE score using the MAE definition between the original data and the predictions for each horizon\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame containing h weeks ahead prediction for each week\n",
    "    y : str\n",
    "        the forecasted variable\n",
    "    file_name: str\n",
    "        the file name for the data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with MAE scores for each horizon and the average MAE score.\n",
    "        \n",
    "    \"\"\"  \n",
    "    df_US = pd.read_csv(file_name)\n",
    "    df_US.index = pd.to_datetime(df_US['date'])\n",
    "    h_level = df_final_forecast.columns.to_list()\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = df_US.loc[df_final_forecast.index][y]\n",
    "        y_pred = df_final_forecast[cols]\n",
    "        value = mae(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0db12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sMAPE         new_deaths\n",
      "h=1      12.793226\n",
      "h=2      18.264951\n",
      "h=3      24.747963\n",
      "h=4      33.405157\n",
      "Average      22.30\n",
      "MAE           new_deaths\n",
      "h=1      1184.381173\n",
      "h=2      1838.002248\n",
      "h=3      2371.215004\n",
      "h=4      3004.409528\n",
      "Average      2099.50\n"
     ]
    }
   ],
   "source": [
    "#SARIMA cdc results without data alignment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "n_train = 40\n",
    "n_test = 79\n",
    "y = 'new_deaths'\n",
    "file_name = 'covid_weekly_cdc.csv'\n",
    "m = 10\n",
    "p = 4\n",
    "d = 1\n",
    "q = 0\n",
    "ps = 1\n",
    "ds = 0\n",
    "qs = 0\n",
    "h_max = 4\n",
    "temp_results = window_results(n_train, n_test, p, d, q, ps, ds, qs, m, y, h_max, transf,itransf,file_name)\n",
    "df_final_forecast = predict_table(n_test, temp_results, h_max)\n",
    "df_smape_results = smape_results(df_final_forecast, y,file_name)\n",
    "print(\"sMAPE {}\".format(df_smape_results))\n",
    "df_mae_results = mae_results(df_final_forecast, y,file_name)\n",
    "print(\"MAE {}\".format(df_mae_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1637bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smape(df_final_forecast: pd.DataFrame, df_US_CDC: pd.DataFrame, model: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the SMAPE score of SARIMA model using the SMAPE definition by aligning the dates with the CDC data (removing\n",
    "    the missing dates)\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame from SARIMA model\n",
    "    df_US_CDC: pd.DataFrame\n",
    "        the predicted DataFrame from CDC model\n",
    "    model: str\n",
    "        the name of the CDC model\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with SMAPE scores for each horizon and the average SMAPE score for SARIMA model.\n",
    "        \n",
    "    \"\"\" \n",
    "    common_dates = df_final_forecast.index.intersection(df_US_CDC.index)\n",
    "    dates_not_present = df_final_forecast.index.difference(df_US_CDC.index)\n",
    "\n",
    "    df_final_forecast_aligned = df_final_forecast.loc[common_dates]\n",
    "\n",
    "    col_core = 'new_deaths'\n",
    "    df_US = pd.read_csv('covid_weekly_cdc.csv')\n",
    "    df_US.index = pd.to_datetime(df_US['date'])\n",
    "    h_level = df_final_forecast_aligned.columns.to_list()\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = df_US.loc[df_final_forecast_aligned.index][y]\n",
    "        y_pred = df_final_forecast_aligned[cols]\n",
    "        value = smape(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33a30094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae(df_final_forecast: pd.DataFrame, df_US_CDC: pd.DataFrame, model: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the MAE score of SARIMA model using the MAE definition by aligning the dates with the CDC data (removing\n",
    "    the missing dates)\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame from SARIMA model\n",
    "    df_US_CDC: pd.DataFrame\n",
    "        the predicted DataFrame from CDC model\n",
    "    model: str\n",
    "        the name of the CDC model\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with MAE scores for each horizon and the average MAE score for SARIMA model.\n",
    "        \n",
    "    \"\"\" \n",
    "    common_dates = df_final_forecast.index.intersection(df_US_CDC.index)\n",
    "    dates_not_present = df_final_forecast.index.difference(df_US_CDC.index)\n",
    "    df_final_forecast_aligned = df_final_forecast.loc[common_dates]\n",
    "    col_core = 'new_deaths'\n",
    "    df_US = pd.read_csv('covid_weekly_cdc.csv')\n",
    "    df_US.index = pd.to_datetime(df_US['date'])\n",
    "    h_level = df_final_forecast_aligned.columns.to_list()\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = df_US.loc[df_final_forecast_aligned.index][y]\n",
    "        y_pred = df_final_forecast_aligned[cols]\n",
    "        value = mae(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5261ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_results_for_model(df_final_forecast: pd.DataFrame ,y: str, CDC_file: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the sMAPE score of CDC model using the sMAPE definition between the original data and the predictions for each horizon\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame containing h weeks ahead prediction for each week\n",
    "    p : int\n",
    "        the value for auto regression order\n",
    "    CDC_file : str\n",
    "        The path for the CDC data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with SMAPE scores for each horizon and the average SMAPE score.\n",
    "        \n",
    "    \"\"\"  \n",
    "    df_US = pd.read_csv(CDC_file, on_bad_lines='skip')\n",
    "    observed_data = df_US[df_US[\"Model\"]=='observed']\n",
    "    observed_data = observed_data[['Date of Forecasted Point', 'Point']]\n",
    "    observed_data.index = pd.to_datetime(observed_data['Date of Forecasted Point'])\n",
    "    observed_data = observed_data.drop(columns=['Date of Forecasted Point'])\n",
    "    h_level = df_final_forecast.columns.to_list()\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = observed_data.loc[df_final_forecast.index][y]\n",
    "        y_pred = df_final_forecast[cols]\n",
    "        value = smape(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "222921b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_results_for_model(df_final_forecast: pd.DataFrame ,y: str, CDC_file: str)-> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    This function calculates the sMAPE score of CDC model using the sMAPE definition between the original data and the predictions for each horizon\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    df_final_forecast: pd.DataFrame\n",
    "        the predicted DataFrame containing h weeks ahead prediction for each week\n",
    "    p : int\n",
    "        the value for auto regression order\n",
    "    CDC_file : str\n",
    "        The path for the CDC data\n",
    "\n",
    "    Returned Values\n",
    "    ----------\n",
    "    df_results : pd.DataFrame\n",
    "        DataFrame with SMAPE scores for each horizon and the average SMAPE score.\n",
    "        \n",
    "    \"\"\"  \n",
    "    df_US = pd.read_csv(CDC_file, on_bad_lines='skip')\n",
    "    observed_data = df_US[df_US[\"Model\"]=='observed']\n",
    "    observed_data = observed_data[['Date of Forecasted Point', 'Point']]\n",
    "    observed_data.index = pd.to_datetime(observed_data['Date of Forecasted Point'])\n",
    "    observed_data = observed_data.drop(columns=['Date of Forecasted Point'])\n",
    "    h_level = df_final_forecast.columns.to_list()\n",
    "\n",
    "    eval = []\n",
    "    for cols in h_level:\n",
    "        y_true = observed_data.loc[df_final_forecast.index][y]\n",
    "        y_pred = df_final_forecast[cols]\n",
    "        value = mae(y_true, y_pred)\n",
    "        eval.append(value)\n",
    "    eval.append(\"{:.2f}\".format(np.mean(eval)))\n",
    "    df_results = pd.DataFrame(eval, columns=[str(y)])\n",
    "    h_level.append('Average')\n",
    "    df_results.index = h_level\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e40e5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdc_data(model: str, CDC_file: str):\n",
    "    \"\"\" \n",
    "    This function shows the 4 weeks ahead prediction with dates aligned and the results for the CDC model and SARIMA\n",
    "    \n",
    "    Arguments\n",
    "    ----------\n",
    "    model : str\n",
    "        The name of the CDC model\n",
    "    CDC_file : str\n",
    "        The path for the CDC data   \n",
    "    \"\"\" \n",
    "\n",
    "    df_US_CDC = pd.read_csv(CDC_file, on_bad_lines='skip')  # Read the CDC data from the specified file\n",
    "    df_US_CDC = df_US_CDC[(df_US_CDC['Model'] == model)] # Filter the data for the specified model\n",
    "    df_US_CDC = df_US_CDC[['Date Model was run', 'Point']] # Select relevant columns\n",
    "    df_US_CDC['Date Model was run'] = pd.to_datetime(df_US_CDC['Date Model was run'])\n",
    "\n",
    "     # Sort values by 'Date Model was run' and group by the same to align the dates\n",
    "    df_US_CDC = df_US_CDC.sort_values('Date Model was run').groupby('Date Model was run')['Point'].apply(lambda df: df.reset_index(drop=True)).unstack().reset_index()\n",
    "\n",
    "    df_US_CDC.set_index('Date Model was run', inplace=True)\n",
    "    df_US_CDC.columns =['h=1', 'h=2', 'h=3', 'h=4'] # Rename columns to indicate the horizon (h=1 to h=4)\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "\n",
    "    # Filter the dataframe for the specified date range\n",
    "    start_date = pd.to_datetime('2020-12-05')\n",
    "    end_date = pd.to_datetime('2022-06-04')\n",
    "    df_US_CDC_1 = df_US_CDC.loc[start_date:end_date]\n",
    "\n",
    "   # Print results (sMAPE and MAE) for the specified CDC model\n",
    "    print(model)\n",
    "    df_smape_results_model = smape_results_for_model(df_US_CDC_1,\"Point\",CDC_file)\n",
    "    df_smape_results_model.columns = [model] * len(df_smape_results_model.columns)\n",
    "    print(\"{}\".format(df_smape_results_model))\n",
    "    df_mae_results = mae_results_for_model(df_US_CDC_1,\"Point\", CDC_file)\n",
    "    df_mae_results.columns = [''] * len(df_mae_results.columns)\n",
    "    print(\"{}\".format(df_mae_results))\n",
    "\n",
    "    #Print results for SARIMA according to the missing dates in CDC data\n",
    "    print(\"SARIMA\")\n",
    "    smape_result = calculate_smape(df_final_forecast, df_US_CDC_1, model)\n",
    "    print(smape_result)\n",
    "    mae_result = calculate_mae(df_final_forecast, df_US_CDC_1, model)\n",
    "    print(mae_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e54882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIT-LCP\n",
      "           MIT-LCP\n",
      "h=1      14.404509\n",
      "h=2      13.874602\n",
      "h=3      12.332699\n",
      "h=4      15.659168\n",
      "Average      14.07\n",
      "                    \n",
      "h=1      1278.690141\n",
      "h=2      1276.788732\n",
      "h=3      1131.605634\n",
      "h=4      1430.478873\n",
      "Average      1279.39\n",
      "SARIMA\n",
      "        new_deaths\n",
      "h=1      12.902679\n",
      "h=2      18.406593\n",
      "h=3      23.904825\n",
      "h=4      34.152437\n",
      "Average      22.34\n",
      "          new_deaths\n",
      "h=1       1173.96651\n",
      "h=2      1843.061037\n",
      "h=3      2294.944499\n",
      "h=4      3117.443485\n",
      "Average      2107.35\n"
     ]
    }
   ],
   "source": [
    "#define the CDC file name and call the method to display results for the specified model and SARIMA\n",
    "CDC_file = 'concatenated_CDC_20_21_22_23.csv'\n",
    "cdc_data(\"MIT-LCP\", CDC_file )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88887ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category 1 models\n",
    "# cdc_data(\"BPagano\", CDC_file)\n",
    "# cdc_data(\"Columbia\", CDC_file)\n",
    "# cdc_data(\"MIT-LCP\", CDC_file)\n",
    "# cdc_data(\"CovidComplete\", CDC_file)\n",
    "# cdc_data(\"ESG\", CDC_file)\n",
    "# cdc_data(\"GT-DeepCOVID\", CDC_file)\n",
    "# cdc_data(\"JHU-APL\", CDC_file)\n",
    "# cdc_data(\"Karlen\", CDC_file)\n",
    "# cdc_data(\"MIT-ORC\", CDC_file)\n",
    "# cdc_data(\"MOBS\", CDC_file)\n",
    "# cdc_data(\"PSI\", CDC_file)\n",
    "# cdc_data(\"UCSD-NEU\", CDC_file)\n",
    "# cdc_data(\"UM\", CDC_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc38130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Category 2 models\n",
    "# cdc_data(\"Covid19Sim\", CDC_file)\n",
    "# cdc_data(\"IHME\", CDC_file)\n",
    "# cdc_data(\"JHU-IDD\", CDC_file)\n",
    "# cdc_data(\"Microsoft\", CDC_file)\n",
    "# cdc_data(\"MIT-ISOLAT\", CDC_file)\n",
    "# cdc_data(\"QJHong\", CDC_file)\n",
    "# cdc_data(\"UMass-MB\", CDC_file)\n",
    "# cdc_data(\"Columbia-UNC\", CDC_file)\n",
    "# cdc_data(\"DDS\", CDC_file)\n",
    "# cdc_data(\"IEM\", CDC_file)\n",
    "# cdc_data(\"ISU\", CDC_file)\n",
    "# cdc_data(\"JCB\", CDC_file)\n",
    "# cdc_data(\"JHU-CSSE\", CDC_file)\n",
    "# cdc_data(\"LANL\", CDC_file)\n",
    "# cdc_data(\"LUcompUncertLab\", CDC_file)\n",
    "# cdc_data(\"Masaryk\", CDC_file)\n",
    "# cdc_data(\"NotreDame-Mobility\", CDC_file)\n",
    "# cdc_data(\"Oliver-Wyman\", CDC_file)\n",
    "# cdc_data(\"RPI-UW\", CDC_file)\n",
    "# cdc_data(\"UA\", CDC_file)\n",
    "# cdc_data(\"UCLA\", CDC_file)\n",
    "# cdc_data(\"UCM\", CDC_file)\n",
    "# cdc_data(\"UGA-CEID\", CDC_file)\n",
    "# cdc_data(\"UpstateSU\", CDC_file)\n",
    "# cdc_data(\"UT\", CDC_file)\n",
    "# cdc_data(\"Ensemble\", CDC_file)\n",
    "# cdc_data(\"ERDC\", CDC_file)\n",
    "# cdc_data(\"LSHTM\", CDC_file)\n",
    "# cdc_data(\"LNQ\", CDC_file)\n",
    "# cdc_data(\"UCLA\", CDC_file)\n",
    "# cdc_data(\"UCM\", CDC_file)\n",
    "# cdc_data(\"UGA-CEID\", CDC_file)\n",
    "# cdc_data(\"UpstateSU\", CDC_file)\n",
    "# cdc_data(\"UT\", CDC_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
